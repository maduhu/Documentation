# L1P Service Logging

## Introduction
This document provides L1P service logging guidelines in order to provide end-end traceability of interactions, aid in troubleshooting and publish metrics to the backend

### Desired Goals
* End-to-end Traceability of a particular transaction
* Understand service behavior
* Debuggging
* Metrics for a particular transaction

#### General:
All logs statement must begin with **ISO8601 compliant timestamp**.  The timestamp must have millisecond resolution.  It should be follwed by a log level.  Available logs levels are 
**ERROR, WARN, INFO, DEBUG**  For example
```
2017-04-28T17:16:20.561Z INFO ilp-routing:routing-tables debug bumping route ledgerA: levelone.dfsp1.  ledgerB:   nextHop: levelone.ist.dfsp2
```
#### 1. End-to-end Traceability:  
To provide end-to-end traceability of Level One payment related interactions, L1P components shall include **L1p-Trace-Id** in all log statements where available.  The following
snippet must be included in all of the log lines: `L1p-Trace-Id=<current_trace_id>` For a given unit of work, related interactions between services,
the L1p-Trace-Id is required to be unique.  It is recommended that UUID be used for uniqueness requirement.  This would allow to quickly retrieve
all logging for a given L1p-Trace-Id.    
 
#### 2. Rest Service Calls:  
All Rest Service calls must include **L1p-Trace-Id** as a header HTTP Header.  The value of this header must be set to *Payment ID* for all payment interactions.
For all non-payment interaction the originating DFSP must generate and use an UUID for the value of the header.  In the case where the **L1p-Trace-Id** is not present
as a header, an error needs to be logged with context about the call with the missing header.  The service must set the **L1p-Trace-Id** header with appropriate value 
whether the current interaction is during the course of processing a payment or not.

#### 3. Web Socket Notifications:  
[To Be Filled based on information from Ripple.]

#### 4. Addtional Context in Logs
It is recommended to log other identifiers that can help retrieve logs statement across multiple layers in the Level One stack. 
Some examples are Transfer Id, User ID (USSD id, email, login name), AppName, and AccountId etc.  `Relevant-Id=<id_value>`
  
#### 5. Metrics Logging
Logs can be used to publish metrics to metrics service.  There are 2 types of metrics that are supported.  The details about supported
metrics are available [here](https://github.com/LevelOneProject/interop-metrics-ui/blob/master/available-metrics.md).  The snippet below shows the systax for publishing metrics:
  
  1. Counter
    ```
    ... L1P_METRIC_COUNTER:[environment.application-instanceid.counter.name] ...
    ```
    where L1P_METRIC_COUNTER is a keyword followed by a colon and the desired metric name* is within [ ].  This would increment the 
    counter identified by metric name by 1.
  1. Timer
    ```
    ... L1P_METRIC_TIMER:[environment.application-instanceid.timer.name][50] ...
    ```
    where L1P_METRIC_TIMER is a keyword followed by a colon, the desired metric name* is within [ ] and timed value in millisenconds with [ ].  
    This would add the time value in milliseconds to timer identified by metric name*.

  \* metric name is composed of 3 elements that separated by a period.  
  1. environment which captures where the application is runnning e.g. _dfsp1-test, dfsp2-qa_ etc.
  1. application instance id which should identify the process
  1. metric name which could contain alpahnumeric characters and could have java package name style prefix
  
### Kibana User Guide

How to use Kibana, its dashboards and query language for L1P tracing and debugging purposes.

Kibana is the ELK Stack (Elastic Stack) window into the Elasticsearch data. It allows you to monitory, query, visualize and create reports on Elasticsearch data. This document is a L1P Kibana User Guide that will show how to use Kibana for the most common L1P use cases. Kibana features used at L1P projects will be described and then specific use cases will be described in detail.

#### Kibana Dashboards and Visualizations

Kibana allows you to create visualizations based on the Elasticsearch data. Furthermore, Kibana allows you to create dashboards based on one or more visualizations. 

Elasticsearch data is generated by the several components:
•	Logstash
•	Filebeat
•	Metricbeat
•	Heartbeat

For the data generated by the Beats family of shippers Kibana also contains out of the box Dashboards and Visualizations. These come prepackaged as part of the given Beat family shipper. After installing the given Beats family shipper its dashboards and visualizations can be imported.

##### Dashboards Import

Following are the scripts to install the Beats family shipper dashboards:

# /usr/share/filebeat/scripts/import_dashboards
# /usr/share/metricbeat/scripts/import_dashboards
# /usr/share/heartbeat/scripts/import_dashboards

In order to access the visualization and dashboards that are imported by these scripts, go to Kibana and navigate to the Visualizations or Dashboards menu options at the left hand menu.

##### Access to Kibana via NGINX on your browser
	
http://EC2_INSTANCE_URL

Enter username/password kibanaadmin/l1p (letter “l”, number “1” and letter “p”)

#### L1P Kibana Use Cases

##### How to login into Kibana?

To login into kibana go to the following URL:

http://ec2-54-71-228-163.us-west-2.compute.amazonaws.com/

with username/password kibanaadmin/l1p.

##### How to monitor logs?

Follow the following steps:

1.	Navigate to “Discover” menu
2.	Expand Time Range, by clicking the “Time picker” icon on top right corner
3.	Set Time Range, pick between Quick, Relative and Absolute modes and set time range
4.	Enter your search criteria (e.g. L1p-Trace-Id)
5.	Perform search
6.	Review logs returned

##### How to set time range?

By default, Kibana will show you logs for the last 15 min. To set the time range from the Discover Kibana page click on the area where with the “Time picker” icon on the top right corner. This will expand the “Time Range” control panel down containing three different modes to set the time range; “Quick”, “Relative” and “Absolute” as shown in screenshots below.


##### How to enable auto refresh of search results?

Search results can be set to auto refresh, so your search results and visualizations do not contain stale data. Optionally, you can manually refresh results by clicking “Refresh”. The Auto-refresh can be enabled by clicking the “Time picker” icon, clicking the “Auto-refresh” link and then set it to on and specify the refresh rate.


##### How change to which indices you are searching?

When you submit a search request, the indices that match the currently-selected index pattern are searched. The current index pattern is shown below the toolbar. To change which indices you are searching, click the index pattern and select a different index pattern. NOTE: By default, only 1 index pattern is shown, you must click the arrow to expand the index section to show you the different indexes available.


##### How to add/remove fields from Kibana’s Discover window to monitor logs?

Navigate to the Kibana Discover page and hover over the field you would like to add/remove from the search results table and click the add/remove button.


##### How to trace a L1P transaction based on its L1p-Trace-Id?

Navigate to the Kibana Discover page and enter a search criterial like:

L1p-Trace-Id=d349c18b-e4ea-4913-b2f8-0b9dcd2f2293


##### How to monitor transaction duration between l1p_components?

A Kibana Visualization on top of the custom l1p_index was created for this purpose and can be accessed by navigating to Kibana Visualize page and selecting the “Transaction Details” link. NOTE: Once the trace id is contained at all component and services logs this table will correctly display the durations. 


##### How to save a search, how to open a saved search and how to manage saved searches?

Kibana allows you to save a search criteria. From the Kibana Discover page just hit the “Save” link on the top right hand corner just before the “Time Picker” icon to save your search. To access your saved search, hit the “Open” link. To delete or edit your save search hit the “Open” link and then the “Manage Saved Searches” link.

#### Reference to Kibana's Official Documentation

https://www.elastic.co/guide/en/kibana/current/introduction.html
